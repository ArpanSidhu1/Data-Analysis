{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88bfe90d",
   "metadata": {},
   "source": [
    "# Sales Analysis \n",
    "Merging 12 months of Sales data into a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c988a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "df=pd.read_csv(\"D:\\\\ONLINE_DATASET\\\\keith\\\\Sales_data\\\\Sales_April_2019.csv\")\n",
    "#print(df.shape)\n",
    "df1=pd.read_csv(\"D:\\\\ONLINE_DATASET\\\\keith\\\\Sales_data\\\\Sales_May_2019.csv\")\n",
    "#print(df1.shape)\n",
    "df2=pd.read_csv(\"D:\\\\ONLINE_DATASET\\\\keith\\\\Sales_data\\\\Sales_June_2019.csv\")\n",
    "#print(df2.shape)\n",
    "df3=pd.read_csv(\"D:\\\\ONLINE_DATASET\\\\keith\\\\Sales_data\\\\Sales_July_2019.csv\")\n",
    "#print(df3.shape)\n",
    "df4=pd.read_csv(\"D:\\\\ONLINE_DATASET\\\\keith\\\\Sales_data\\\\Sales_August_2019.csv\")\n",
    "#print(df4.shape)\n",
    "df5=pd.read_csv(\"D:\\\\ONLINE_DATASET\\\\keith\\\\Sales_data\\\\Sales_September_2019.csv\")\n",
    "#print(df5.shape)\n",
    "df6=pd.read_csv(\"D:\\\\ONLINE_DATASET\\\\keith\\\\Sales_data\\\\Sales_October_2019.csv\")\n",
    "#print(df6.shape)\n",
    "df7=pd.read_csv(\"D:\\\\ONLINE_DATASET\\\\keith\\\\Sales_data\\\\Sales_November_2019.csv\")\n",
    "#print(df7.shape)\n",
    "df8=pd.read_csv(\"D:\\\\ONLINE_DATASET\\\\keith\\\\Sales_data\\\\Sales_December_2019.csv\")\n",
    "#print(df8.shape)\n",
    "df9=pd.read_csv(\"D:\\\\ONLINE_DATASET\\\\keith\\\\Sales_data\\\\Sales_January_2019.csv\")\n",
    "#print(df9.shape)\n",
    "df10=pd.read_csv(\"D:\\\\ONLINE_DATASET\\\\keith\\\\Sales_data\\\\Sales_February_2019.csv\")\n",
    "#print(df10.shape)\n",
    "df11=pd.read_csv(\"D:\\\\ONLINE_DATASET\\\\keith\\\\Sales_data\\\\Sales_March_2019.csv\")\n",
    "#print(df11.shape)\n",
    "merged_sales=pd.concat([df9,df10,df11,df,df1,df2,df3,df4,df5,df6,df7,df8],axis=0) # concat()- is used to concatenate more then two dataset ,  and there is one also called merge syntax which is used when we have to merge on the basis of primary key (df.merge(df1,on=[\"\"]))\n",
    "print(merged_sales.shape)\n",
    "#merged_sales.to_csv(\"D:\\\\ONLINE_DATASET\\\\keith\\\\Sales_data\\\\Merged_sales.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34543465",
   "metadata": {},
   "source": [
    "# Second Method to merge all the files using loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbec441",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=[file for file in os.listdir('D:\\\\ONLINE_DATASET\\\\keith\\\\Sales_data')]\n",
    "all_months_data=pd.DataFrame()\n",
    "for file in files:\n",
    "        if file==\"Merged_sales.csv\":\n",
    "            pass\n",
    "        else:\n",
    "                df=pd.read_csv(\"D:\\\\ONLINE_DATASET\\\\keith\\\\Sales_data\\\\\"+file)\n",
    "                all_months_data=pd.concat([all_months_data,df])\n",
    "print(all_months_data.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3619010",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"D:\\\\ONLINE_DATASET\\\\keith\\\\Sales_data\\\\Merged_sales.csv\")\n",
    "df.set_index(\"INDEX\",inplace=True)\n",
    "#df.head()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a60301b",
   "metadata": {},
   "source": [
    "## Q-1 What was the Best Month For Sales ?  How much was earned that Month ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbde7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)\n",
    "#df.drop([\"Purchase Address\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f94cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan_sum= 0\n",
    "for row in df[(df[\"Order Date\"] >= '01/01/2019') & (df[\"Order Date\"] <= \"01/31/2019\")].iterrows():\n",
    "    Jan_sum += float(row[1][\"Quantity Ordered\"]) * float(row[1][\"Price Each\"])\n",
    "print(\"Sales of January  :  \",  round(Jan_sum,2))    \n",
    "\n",
    "Feb_sum=0\n",
    "for row in df[(df[\"Order Date\"] >= \"02/01/2019\") & (df[\"Order Date\"] <= \"02/30/2019\")].iterrows():\n",
    "    Feb_sum += float(row[1][\"Quantity Ordered\"]) * float(row[1][\"Price Each\"])\n",
    "print(\"Sales of Feburary : \", round(Feb_sum,2))    \n",
    "    \n",
    "Mar_sum=0\n",
    "for row in df[(df[\"Order Date\"] >= \"03/01/2019\") & (df[\"Order Date\"] <= \"03/31/2019\")].iterrows():\n",
    "    Mar_sum += float(row[1][\"Quantity Ordered\"]) * float(row[1][\"Price Each\"])\n",
    "print(\"Sales of March    : \", round(Mar_sum,2))       \n",
    "\n",
    "Apr_sum=0\n",
    "for row in df[(df[\"Order Date\"] >= \"04/01/2019\") & (df[\"Order Date\"] <= \"04/31/2019\")].iterrows():\n",
    "    Apr_sum += float(row[1][\"Quantity Ordered\"]) * float(row[1][\"Price Each\"])\n",
    "print(\"Sales of April    : \", round(Apr_sum,2))    \n",
    "\n",
    "May_sum=0\n",
    "for row in df[(df[\"Order Date\"] >= \"05/01/2019\") & (df[\"Order Date\"] <= \"05/31/2019\")].iterrows():\n",
    "    May_sum += float(row[1][\"Quantity Ordered\"]) * float(row[1][\"Price Each\"])\n",
    "print(\"Sales of May    : \", round(May_sum,2))       \n",
    "\n",
    "June_sum=0\n",
    "for row in df[(df[\"Order Date\"] >= \"06/01/2019\") & (df[\"Order Date\"] <= \"06/31/2019\")].iterrows():\n",
    "    June_sum += float(row[1][\"Quantity Ordered\"]) * float(row[1][\"Price Each\"])\n",
    "print(\"Sales of June    : \", round(June_sum,2))  \n",
    "\n",
    "July_sum=0\n",
    "for row in df[(df[\"Order Date\"] >= \"07/01/2019\") & (df[\"Order Date\"] <= \"07/31/2019\")].iterrows():\n",
    "    July_sum += float(row[1][\"Quantity Ordered\"]) * float(row[1][\"Price Each\"])\n",
    "print(\"Sales of July    : \", round(July_sum,2))  \n",
    "\n",
    "August_sum=0\n",
    "for row in df[(df[\"Order Date\"] >= \"08/01/2019\") & (df[\"Order Date\"] <= \"08/31/2019\")].iterrows():\n",
    "    August_sum += float(row[1][\"Quantity Ordered\"]) * float(row[1][\"Price Each\"])\n",
    "print(\"Sales of August   : \", round(August_sum,2))  \n",
    "\n",
    "Sep_sum=0\n",
    "for row in df[(df[\"Order Date\"] >= \"09/01/2019\") & (df[\"Order Date\"] <= \"09/31/2019\")].iterrows():\n",
    "    Sep_sum += float(row[1][\"Quantity Ordered\"]) * float(row[1][\"Price Each\"])\n",
    "print(\"Sales of September    : \", round(Sep_sum,2))  \n",
    "\n",
    "Oct_sum=0\n",
    "for row in df[(df[\"Order Date\"] >= \"10/01/2019\") & (df[\"Order Date\"] <= \"10/31/2019\")].iterrows():\n",
    "    Oct_sum += float(row[1][\"Quantity Ordered\"]) * float(row[1][\"Price Each\"])\n",
    "print(\"Sales of October    : \", round(Oct_sum,2)) \n",
    "\n",
    "Nov_sum=0\n",
    "for row in df[(df[\"Order Date\"] >= \"11/01/2019\") & (df[\"Order Date\"] <= \"11/31/2019\")].iterrows():\n",
    "    Nov_sum += float(row[1][\"Quantity Ordered\"]) * float(row[1][\"Price Each\"])\n",
    "print(\"Sales of November    : \", round(Nov_sum,2)) \n",
    "\n",
    "Dec_sum=0\n",
    "for row in df[(df[\"Order Date\"] >= \"12/01/2019\") & (df[\"Order Date\"] <= \"12/31/2019\")].iterrows():\n",
    "    Dec_sum += float(row[1][\"Quantity Ordered\"]) * float(row[1][\"Price Each\"])\n",
    "print(\"Sales of December    : \", round(Dec_sum,2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb4bb04",
   "metadata": {},
   "source": [
    "# Ans 1 :  Best Month For Sales Was December as it had 2816272 /- rupees of sales . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cad193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Keith Method\n",
    "all_data=df\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5277df59",
   "metadata": {},
   "source": [
    "# Cleaning the Data\n",
    "   #### dropping rows of Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ecd38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_df= all_data[all_data.isna().any(axis=1)]\n",
    "nan_df.head()\n",
    "\n",
    "all_data=all_data.dropna(how=\"all\")\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d1f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data[all_data[\"Order Date\"].str[0:2]!=\"Or\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab9d802",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"Quantity Ordered\"] = pd.to_numeric(all_data[\"Quantity Ordered\"])\n",
    "all_data[\"Price Each\"] = pd.to_numeric(all_data[\"Price Each\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01356d1f",
   "metadata": {},
   "source": [
    "Augmenting data with Additional Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef61727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Month Column\n",
    "all_data[\"Month\"]=all_data[\"Order Date\"].str[0:2]\n",
    "all_data[\"Month\"]=all_data[\"Month\"].astype(int)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff48e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Sales COlumns\n",
    "print(all_data.columns)\n",
    "all_data[\"Sales\"]= (all_data[\"Quantity Ordered\"]) * (all_data[\"Price Each\"])\n",
    "all_data.head()\n",
    "m_data=all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f84d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=all_data.groupby(by=\"Month\")\n",
    "all_data=all_data.sum()\n",
    "print(all_data)\n",
    "import matplotlib.pyplot as plt\n",
    "l=[\"jan\",\"feb\",\"mar\",\"apr\",\"may\",\"june\",\"july\",\"aug\",\"sep\",\"oct\",\"nov\",\"dec\"]\n",
    "plt.bar(l,all_data[\"Sales\"],color=[\"black\",\"white\"],edgecolor=\"k\")\n",
    "plt.xlabel(\"MONTHS\")\n",
    "plt.ylabel(\"SALES\")\n",
    "plt.title(\"Analysis of Sales As per Month\",fontsize=\"14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4afeef8",
   "metadata": {},
   "source": [
    "# December was the best month for sales as there was a sale of 4613443 rupees only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979c3c01",
   "metadata": {},
   "source": [
    "# Question :  2 - What City had the highest Number of Sales ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5668c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6826548",
   "metadata": {},
   "source": [
    "### Adding a column named City containing the city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27416024",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sales['City'] = merged_sales['Purchase Address'].str.split(',').str[1].str.strip()\n",
    "merged_sales.head()\n",
    "# decode the city line\n",
    "# merged_sales['Purchase Address'] - it is representing the column of address from which i had to slice the city.\n",
    "# str.split(',') - split the string into commas now the address is divivded into 3 segments : 1) house address 2) city 3) code\n",
    "# str[1] - It is returing the string from the three whose index is 1 \n",
    "# str.strip() -  it is used to remove the extra white spaces of spaces in a string after applying it only returns the city name without any extra space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a13aa13",
   "metadata": {},
   "source": [
    "### Cleaning the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sales=merged_sales.dropna(how=\"all\")\n",
    "merged_sales.head()\n",
    "print(merged_sales.columns)\n",
    "merged_sales[\"Quantity Ordered\"]=pd.to_numeric(merged_sales[\"Quantity Ordered\"],errors='coerce')\n",
    "merged_sales[\"Price Each\"]=pd.to_numeric(merged_sales[\"Price Each\"],errors='coerce')\n",
    "merged_sales[\"Sales\"]= merged_sales[\"Quantity Ordered\"] * merged_sales[\"Price Each\"]\n",
    "merged_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ebdd52",
   "metadata": {},
   "source": [
    "GROUPING BY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0fa54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Group = merged_sales.groupby(\"City\").sum()\n",
    "#print(Group)\n",
    "Sales=Group[\"Sales\"].tolist()\n",
    "City1=[\"Atlanta\",\"Austin\",\"Boston\",\"Dallas\",\"Los Angeles\",\"New York City\",\"Portland\",\"San Francisco\",\"Seattle\"]\n",
    "print(Sales)\n",
    "print(City1)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 15))\n",
    "plt.bar(City1,Sales,edgecolor=\"k\")\n",
    "plt.xlabel(\"City1\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.title(\"SALES IN DIFFERENT CITIES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e0f62e",
   "metadata": {},
   "source": [
    "## Ans - 2 San Franciso was the city of highest Sales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650b3a4f",
   "metadata": {},
   "source": [
    "## Question - 3 What time should we display advertisments to maximize likelihood of customer's buying product ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6d19c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data['Order Date'] =  pd.to_datetime(m_data['Order Date']) # it is used to convert a order date into 2 different index date and time.\n",
    "m_data.head() \n",
    "m_data[\"Hour\"] = m_data[\"Order Date\"].dt.hour\n",
    "m_data[\"Minutes\"] = m_data[\"Order Date\"].dt.minute\n",
    "busiest_hour=m_data[\"Hour\"].value_counts().idxmax() # here value counting is giving all the hours counts and index max is returning the busiest hour.\n",
    "print(\"The Busiest Hour for Sales was  : \",busiest_hour)\n",
    "m_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d47f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = [hour for hour, df in m_data.groupby(\"Hour\")]\n",
    "\n",
    "plt.plot(hours, m_data.groupby(\"Hour\").count())\n",
    "\n",
    "plt.xticks(hours)\n",
    "\n",
    "plt.grid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87e9fe3",
   "metadata": {},
   "source": [
    "### Answer 3 :  Our Recommendation is either 11:00 AM or 19:00 PM as sales was at it's peak at that time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272c3b5f",
   "metadata": {},
   "source": [
    "# Question -  4 What Products most often Sell Together ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9349e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data.head()\n",
    "p_data=m_data\n",
    "# with the help of order_id we can see the products that are buyed together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b87576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = m_data[m_data['Order ID'].duplicated(keep=False)]\n",
    "# here it is going to create a dataframe in which all the duplicated Order ID are going to apppear one after the another.\n",
    "df.head()\n",
    "df['Grouped'] = df.groupby('Order ID')[\"Product\"].transform(lambda x : ','.join(x))\n",
    "# Here it first grouping it by Order ID and then Adding the products on both the Order Id by their Names and then putting into the column Grouped.\n",
    "df.head()\n",
    "Maximum = df['Grouped'].value_counts()\n",
    "print(Maximum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb59dd",
   "metadata": {},
   "source": [
    "###  Answer 4 : The Products that are most often sell together was Iphone, Lightning Charging cable\n",
    "### ii) The Poduct that are second are : Google Phone ,  USB-C Charging Cable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161157c2",
   "metadata": {},
   "source": [
    "#### Answering question number 4 with keith galle method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfde976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "count = Counter()\n",
    "\n",
    "for row in df['Grouped']:\n",
    "    row_list= row.split(',')\n",
    "    count.update(Counter(combinations(row_list, 2)))\n",
    "count.most_common(10)\n",
    "\n",
    "# here we can see the answer \n",
    "# Counter is used as a specialized Container that allows counting the Occurances of elements in a collection.\n",
    "# Count will the store the count of combinations.\n",
    "# for row in df['Grouped'] will iterate over the whole columns\n",
    "# row_list= row.split(,) - it assumes that element in the list are comma seprated\n",
    "# count.update(Counter(combinations(row_list, 2))) -  This line generates all possible combinations of size 2 from the row_list and updates the count counter ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fa729a",
   "metadata": {},
   "source": [
    "## Question - 5 : What product sold the most and why do you think it sold the most ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63181ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data.head()\n",
    "Quantity = p_data['Quantity Ordered','Product'].value_counts()\n",
    "print(Quantity)\n",
    "# it "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab45094c",
   "metadata": {},
   "source": [
    "## Answer 5  : The Product Sold the most is an Usb Cable as it is the most basic one and also \n",
    "## commonly available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc56414",
   "metadata": {},
   "source": [
    "### Solving answer 5 by keith gali method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcae4984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(p_data.columns)\n",
    "p1_data= m_data.groupby(\"Product\")\n",
    "Quantity_Ordered = p1_data.sum()['Quantity Ordered']\n",
    "\n",
    "p2_data=m_data.groupby('Product').mean()['Price Each']\n",
    "#print(p2_data)\n",
    "products= [product for product, df in p1_data]\n",
    "#print(products)\n",
    "fig,ax1= plt.subplots()\n",
    "ax1.bar(products,Quantity_Ordered,color='green')\n",
    "ax1.set_ylabel(\"Quantity of Products\",color='green')\n",
    "ax2= ax1.twinx()\n",
    "ax1.set_xlabel(\" All Products \")\n",
    "ax2.plot(products,p2_data,color='red')\n",
    "ax2.set_ylabel('Cost of Each Product',color='red')\n",
    "ax1.set_xticklabels(products,rotation='vertical',size=8)\n",
    "plt.show()\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e7131f",
   "metadata": {},
   "source": [
    " ## How to mark 2 plots like above\n",
    "    \n",
    "    1) plt.subplots() is defined to ax1 and fig i don't know what fig and ax1 is axis 1\n",
    "    2) if you want to set ylabel or xlabel the syntax is  :  ax1.set_xlabel()\n",
    "    3) ax2= ax1.twinx (To make another twin ax2 or we can say axis 2)\n",
    "    4) then you can plot line with the help of it like ax2.plot and that all.\n",
    "    5) if you want the print the x label horizontally the ax1.set_xticklables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b75ac3",
   "metadata": {},
   "source": [
    "### Answer 5 : So the Most Commonly Used Product is AAA batteries 4 Pack  according to keith gali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be42e814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
